{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land degradation <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n",
    "* **Products used:** \n",
    "[ga_ls8c_wofs_2](https://explorer.digitalearth.africa/ga_ls8c_wofs_2), \n",
    "[s2_12a](https://explorer.digitalearth.africa/s2_12a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "[Surface mining](https://americanmineservices.com/types-of-surface-mining) refers to the removal of the terrain surface to access minerals underneath. In particular, surface mining is used to retrieve sand, gravel, stones, coal, iron and other metals. Surface mining is often more cost-effective than gouging tunnels and subterranean shafts to access minerals underground.\n",
    "\n",
    "Although surface mining contributes to the source of income for a country, illegal mining operations can result in deleterious impacts on farmlands, forests, and water bodies. Government officials are making efforts to identify areas of illegal mining activities and to restore the mining sites. This notebook demonstrates a method for identifying regions where land degradation and water loss has occurred. This may indicate mining is taking place. The regions identified do not necessarily identify areas of illegal mining activities, further verification by government agencies is required to discern illegal vs legal mining operations.\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "Mining operations often result in the clearing of vegetation and the develpment of water bodies for processing ore. These land-use changes can be identified by finding region where changes in vegetation and water extents occurr. Using remote sensing images Sentinel-2 and DE Africa's Water Observations from Space (WOfS) product, this notebook finds regions where coincident changes in vegetation and water extent occur. The coupling of these two changes may reveal locations of illegal mining, or general land degradation. However, the user should not accept the accuracy of the results but should conduct ground validation testing to assess accuracy. \n",
    "\n",
    "In most cases, these algorithms can be used to identify clusters of pixels that have experienced change and allow targeted investigation of those areas by local or regional governments.\n",
    "\n",
    "The notebook demonstrates how to:\n",
    "\n",
    "1. Load data for a given location and time period\n",
    "2. Calculate the vegetation change using NDVI\n",
    "3. Compare the water extent for two time periods\n",
    "4. Combine vegetation change and water extent change into one plot to show possible illegal mining areas\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import RdYlGn\n",
    "from datacube.utils import geometry\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "from deafrica_datahandling import load_ard, wofs_fuser, mostcommon_crs\n",
    "from deafrica_plotting import display_map, map_shapefile, rgb\n",
    "from deafrica_spatialtools import xr_rasterize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Land_degradation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Dask cluster\n",
    "\n",
    "Dask can be used to better manage memory use and conduct the analysis in parallel. \n",
    "For an introduction to using Dask with Digital Earth Africa, see the [Dask notebook](../Beginners_guide/08_Parallel_processing_with_dask.ipynb).\n",
    "\n",
    ">**Note**: We recommend opening the Dask processing window to view the different computations that are being executed; to do this, see the *Dask dashboard in DE Africa* section of the [Dask notebook](../Beginners_guide/08_Parallel_processing_with_dask.ipynb).\n",
    "\n",
    "To activate Dask, set up the local computing cluster using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35449</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/nanaboamah/proxy/8787/status' target='_blank'>/user/nanaboamah/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>15</li>\n",
       "  <li><b>Memory: </b>104.37 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35449' processes=1 threads=15, memory=104.37 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "There is also a parameter to define how the data is split in time. Note you must specify either the path of the shapefile or use the lattitude, longitude and buffer.\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "* `vector_file`: The file path and name of a shapefile containing the extent. \n",
    "* `latitude`: The latitude at the centre of your Area of Interest (AOI) (e.g. `0.02`).\n",
    "* `longitude`: The longitude at the centre of your AOI (e.g. `35.425`).\n",
    "* `buffer`: The number of degrees to load around the central latitude and longitude.\n",
    "For reasonable loading times, set this as `0.1` or lower.\n",
    "* `time`: The date range to analyse (e.g. `('2015-01-01', '2019-09-01')`).\n",
    "For reasonable results, the range should span at least two years to minimise the impact of seasonal changes.\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example covers part of the Northern Tindiret Forest Reserve, Kenya, and uses the shapefile provided in **Supplementary Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_year = 2013\n",
    "analysis_year = 2017\n",
    "\n",
    "# vector_file = None\n",
    "vector_file = \"data/upperdenkyira.shp\"\n",
    "\n",
    "if vector_file:\n",
    "    # Read shapefile into a GeoDataFrame\n",
    "    gdf = gpd.read_file(vector_file)\n",
    "\n",
    "    # Convert all of the shapes into a datacube geometry\n",
    "    geom = geometry.Geometry(gdf.unary_union, gdf.crs)\n",
    "    \n",
    "else:\n",
    "    longitude = -1.892\n",
    "    latitude = 6.31744\n",
    "    buffer = 0.05\n",
    "    \n",
    "    lat_range = (latitude-buffer, latitude+buffer)\n",
    "    lon_range = (longitude-buffer, longitude+buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below renders a map that can be used to orient yourself with the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a37cc50a7b42028a13661a80013507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718b9afd9bdd455ebbf40a35043de233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[6.106385415185879, -1.9992221151967147], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not vector_file:\n",
    "    display_map(lon_range, lat_range)\n",
    "else:\n",
    "    map_shapefile(gdf, attribute=gdf.columns[0], fillOpacity=0, weight=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data from the Data Cube \n",
    "    \n",
    "The first step in the analysis is to load Landsat data for the specified area of interest and time range. \n",
    "\n",
    "The code below will create a query dictionary for our region of interest, find the correct `crs` object for the area of interest, and then load the Landsat data using the `load_ard` function.\n",
    "For more information, see the [Using load_ard notebook](../Frequently_used_code/Using_load_ard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for USGS Collection 1\n",
      "Finding datasets\n",
      "    ls8_usgs_sr_scene\n",
      "Applying pixel quality/cloud mask\n",
      "Re-scaling Landsat C1 data\n",
      "Returning 137 time steps as a dask array\n"
     ]
    }
   ],
   "source": [
    "#Create a query object\n",
    "query = {\n",
    "    'group_by': 'solar_day',\n",
    "}\n",
    "\n",
    "if vector_file:\n",
    "    query[\"geopolygon\"] = geom\n",
    "else:\n",
    "    query[\"x\"] = lon_range\n",
    "    query[\"y\"] = lat_range\n",
    "\n",
    "query['resolution'] = (-10, 10)\n",
    "\n",
    "product = 'ls8_usgs_sr_scene' #'s2_l2a'\n",
    "# Identify the most common projection system in the input query\n",
    "output_crs = mostcommon_crs(dc=dc, product=product, query=query)\n",
    "\n",
    "ds = load_ard(dc=dc,\n",
    "              products=[product], output_crs=output_crs,\n",
    "              dask_chunks={'time':1,'x':2000,'y':2000},\n",
    "              measurements=[\"red\",\"green\",\"blue\",\"nir\",\"swir1\",\"swir2\"],\n",
    "              time=(f'{baseline_year}', f'{analysis_year}'),\n",
    "              scaling='normalised',\n",
    "              **query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute geomedian for each year\n",
    "For more information about computing geomedians, see the [Generating geomedian composites](../Frequently_used_code/Generating_geomedian_composites.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geomedian = ds.groupby('time.year').map(xr_geomedian)\n",
    "\n",
    "ds_geomedian = ds_geomedian.sel(year=[baseline_year, analysis_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate indices for each year\n",
    "\n",
    "Using the `calculate_indices` functions, NDVI and MNDWI is computed on the geomedian dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geomedian = calculate_indices(ds_geomedian, ['NDVI','MNDWI','WI'], collection='c1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line of code will trigger the delayed computations up to the point using Dask's `.compute()` method. To check the progress of the calculations use the hyperlink printed below the `create_local_dask_cluster()` cell at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geomedian = ds_geomedian.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a mask to each year\n",
    "We will use the polygon from the shapefile to create a mask, so we can work with only the pixels in the area. To convert the vector polygon to a raster mask, we use `xr_rasterize`. For more information on indices, see the [Rasterising vectors & vectorising rasters](/Frequently_used_code/Rasterise_vectorise.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the polygon to a raster that matches our imagery data\n",
    "if vector_file:\n",
    "    mask = xr_rasterize(gdf, ds_geomedian)\n",
    "\n",
    "    # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "    ds_geomedian = ds_geomedian.where(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the anomaly in vegatation for the selected years\n",
    "\n",
    "The anomaly is calculated by subtracting the analysis year data from the baseline data to identifying the change over the two periods.\n",
    "A `vegetation_loss_threshold` is set to pick out areas that vegetation was loss. The threshold can be varied depending on the area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = ds_geomedian.isel(year=0)\n",
    "analysis = ds_geomedian.isel(year=1)\n",
    "\n",
    "parameter_anomaly = analysis.NDVI - baseline.NDVI\n",
    "\n",
    "\n",
    "vegetation_loss_threshold = -0.2\n",
    "# Determine areas with significant deforestation (negative difference)\n",
    "vegetation_loss = parameter_anomaly < vegetation_loss_threshold\n",
    "vegetation_loss['name'] = \"Vegetation_loss\"\n",
    "\n",
    "# Determine areas with significant afforestations (positive difference)\n",
    "vegetation_gain = parameter_anomaly > 0.2\n",
    "vegetation_gain['name'] = \"Vegetation_gain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot baseline RGB, analysis RGB and anomaly products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(18, 16))\n",
    "baseline[['red', 'green', 'blue']].to_array().plot.imshow(ax=ax[0,0], robust=True)\n",
    "analysis[['red', 'green', 'blue']].to_array().plot.imshow(ax=ax[0,1], robust=True)\n",
    "parameter_anomaly.plot(cmap='RdYlGn', ax=ax[1,0], add_colorbar=False)\n",
    "vegetation_loss.plot(cmap='OrRd', ax=ax[1,1],  add_colorbar=False)\n",
    "ax[0,0].set_title('Baseline mean composite')\n",
    "ax[0,1].set_title('Analysis composite')\n",
    "ax[1,0].set_title('Vegetation Anomalies: Red=Loss, Green=Gain')\n",
    "ax[1,1].set_title('Locations of Significant Anomalies-Vegetation loss: Red=Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the area per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_length = query[\"resolution\"][1]  # in metres\n",
    "m_per_km = 1000  # conversion from metres to kilometres\n",
    "area_per_pixel = pixel_length**2 / m_per_km**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total area of pixel, area and percentage of vegetation loss pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels = analysis.NDVI.count(dim=['x', 'y']).values\n",
    "total_vegetation_loss = vegetation_loss.where(vegetation_loss==True).count(dim=['x', 'y']).values\n",
    "\n",
    "total_forest_area = total_pixels * area_per_pixel\n",
    "vegetation_loss_area = total_vegetation_loss * area_per_pixel\n",
    "percentage_vegetation_loss = (total_vegetation_loss/total_pixels) * 100\n",
    "\n",
    "print(f\"Total Area: {total_forest_area:.2f} km sq\")\n",
    "print(f\"Vegetation Loss : {vegetation_loss_area:.2f} km sq\")\n",
    "print(f\"{percentage_vegetation_loss:.2f}% of pixels likely underwent vegetation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the change in water extent using WOFS and MNDWI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WOfS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want the time and spatial extents to match the vegetation change data, we can use the same query defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query['resolution'] =  (-30, 30)\n",
    "\n",
    "# Identify the most common projection system in the input query\n",
    "output_crs = mostcommon_crs(dc=dc, product=[\"ga_ls8c_wofs_2\"], query=query)\n",
    "\n",
    "query['time'] = (f'{baseline_year}')\n",
    "ds_wofs_baseline = dc.load(product=[\"ga_ls8c_wofs_2\"],\n",
    "             output_crs=output_crs,\n",
    "             fuse_func=wofs_fuser,\n",
    "             **query\n",
    "            )\n",
    "\n",
    "query['time'] = (f'{analysis_year}')\n",
    "ds_wofs_analysis = dc.load(product=[\"ga_ls8c_wofs_2\"],\n",
    "             output_crs=output_crs,\n",
    "             fuse_func=wofs_fuser,\n",
    "             **query\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select \"water\" pixels from the WOFS dataset\n",
    "\n",
    "WOfS uses bit flags to identify water and non-water pixels. Water pixels have the value `128`. See [Applying WOfS bitmasking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_water_baseline = ds_wofs_baseline.water.isin([128])\n",
    "\n",
    "ds_water_analysis = ds_wofs_analysis.water.isin([128])\n",
    "\n",
    "if vector_file:\n",
    "    ds_water_baseline = ds_water_baseline.where(mask)\n",
    "    \n",
    "    ds_water_analysis = ds_water_analysis.where(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the area per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_length = query[\"resolution\"][1]  # in metres\n",
    "m_per_km = 1000  # conversion from metres to kilometres\n",
    "area_per_pixel = pixel_length**2 / m_per_km**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate area covered by water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_water_area_baseline = ds_water_baseline.sum(dim=['x', 'y']) * area_per_pixel\n",
    "\n",
    "ds_water_area_analysis = ds_water_analysis.sum(dim=['x', 'y']) * area_per_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select maximum water observed for the two years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_max_water, analysis_max_water = max(ds_water_area_baseline),  max(ds_water_area_analysis)\n",
    "\n",
    "max_water_baseline = ds_water_baseline.sel(time=baseline_max_water.time.values)\n",
    "\n",
    "max_water_analysis = ds_water_analysis.sel(time=analysis_max_water.time.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset array is transform to 1 and 0 using the `astype(int)` function.\n",
    "change = max_water_analysis.astype(int) - max_water_baseline.astype(int)\n",
    "\n",
    "# A threshold greater than 0 is  for area where MNDWI indices is water\n",
    "threshold_value = 0\n",
    "\n",
    "# We set areas where threshold greater than 0 to 1 and others to 0\n",
    "analysis_mndwi = analysis.MNDWI >= threshold_value\n",
    "baseline_mndwi = baseline.MNDWI >= threshold_value\n",
    "\n",
    "#The change is calculated to determine water gain, loss and permanent\n",
    "change_mndwi = analysis_mndwi.astype(int) - baseline_mndwi.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A threshold greater than 0 is  for area where MNDWI indices is water\n",
    "threshold_value = 1.720\n",
    "\n",
    "# We set areas where threshold greater than 0 to 1 and others to 0\n",
    "analysis_wi = analysis.WI >= threshold_value\n",
    "baseline_wi = baseline.WI >= threshold_value\n",
    "change_wi = analysis_wi.astype(int) - baseline_wi.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Results\n",
    "When water(WOFS, WI, MNDWI) and vegetation loss superimposed, the area is classified as Highly potential mining site.\n",
    "For Areas where there was only vegetation loss there is a meduim potential of identifying mining sites at that area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "vegetation_loss = vegetation_loss.where(vegetation_loss==True)\n",
    "mining_area = vegetation_loss.where(change_wi | change | change_mndwi)\n",
    "\n",
    "analysis.NDVI.plot.imshow(cmap='Greys', add_colorbar=False)\n",
    "\n",
    "vegetation_loss.plot.imshow(cmap=ListedColormap(['Brown']), add_colorbar=False)\n",
    "mining_area.plot.imshow(cmap=ListedColormap(['Gold']), add_colorbar=False)\n",
    "\n",
    "\n",
    "plt.legend(\n",
    "        [Patch(facecolor='Gold'), Patch(facecolor='Brown')], \n",
    "        ['Highly Potential Mining Site', 'Medium Potential Mining Site'],\n",
    "        loc = 'upper right'\n",
    "    )\n",
    "\n",
    "plt.title('Possible Mining Areas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaod the end product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cog(deforestaion.astype(float), fname='deforestaion.tif', overwrite=True)\n",
    "write_cog(mining_area.astype(float), fname='mining_area.tif', overwrite=True, nodata=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** November 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DE Africa User Guide's [Tags Index](https://) (placeholder as this does not exist yet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**:  :index:`WOfS`, :index:`deafrica_plotting`, :index:`rgb`, :index:`dea_datahandling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
